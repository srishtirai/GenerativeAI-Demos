{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa1dsRjdDkYF"
      },
      "source": [
        "# Demonstration of LangChain RAG, Input/Output Parsing, and Structured Responses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IAs8PGcFyrt"
      },
      "source": [
        "This section ensures all required libraries are installed before running the notebook.\n",
        "\n",
        "- `langchain` → Used for integrating OpenAI models and FAISS.\n",
        "- `openai` → Allows us to use OpenAI’s GPT models for generating responses.\n",
        "- `faiss-cpu` → Used for storing and retrieving vector embeddings.\n",
        "- `pymupdf` → Helps extract text from PDF documents.\n",
        "- `sentence-transformers` → Converts text into vector embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8PX26-20uTu",
        "outputId": "7c47a438-cb4c-47cd-8aea-d0f3ee9da7aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.60.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.17)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2024.12.14)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.60.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gpt4all) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gpt4all) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gpt4all) (2024.12.14)\n",
            "Downloading gpt4all-2.8.2-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gpt4all\n",
            "Successfully installed gpt4all-2.8.2\n"
          ]
        }
      ],
      "source": [
        "# Install Dependencies\n",
        "!pip install langchain openai faiss-cpu pymupdf gdown\n",
        "!pip install -U langchain-community\n",
        "!pip install tiktoken\n",
        "!pip install --upgrade openai langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Cy2gAFruYXUF"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "import fitz  # PyMuPDF for PDF processing\n",
        "import gdown  # For downloading resume\n",
        "import os\n",
        "from langchain.schema import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kd_7CmRD8Ei"
      },
      "source": [
        "# Building an AI-Powered Resume Q&A System with LangChain\n",
        "\n",
        "###  **This Notebook Demonstrates**\n",
        "This notebook showcases how to build an **AI-powered Q&A system** that allows users to ask questions about a resume document using **LangChain** and **Retrieval-Augmented Generation (RAG)**.\n",
        "\n",
        "\n",
        "\n",
        "* **Retrieval-Augmented Generation (RAG)** – Using FAISS to retrieve relevant resume content before querying OpenAI’s LLM.  \n",
        "* **Input Parsing & Processing** – Cleaning user queries and formatting them for effective retrieval.  \n",
        "* **Output Formatting** – Ensuring structured, readable, and relevant answers.  \n",
        "* **Interactive Q&A System** – Allowing users to ask dynamic questions and receive context-aware answers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePhxF4SrEiNa"
      },
      "source": [
        "## **Load and Process Resume Data**\n",
        "\n",
        "- Extract text from a resume PDF.\n",
        "- Convert the text into a structured format for retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkH8JlXZ05GI",
        "outputId": "5e1cb8d4-b6bf-4151-f039-b59f5725d2e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WxN09mL1KuBQc0VIYm1nVF38Sd0gTMSq\n",
            "To: /content/resume.pdf\n",
            "100%|██████████| 92.8k/92.8k [00:00<00:00, 66.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF opened successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load and Process a resume\n",
        "resume_url = \"https://drive.google.com/uc?id=1WxN09mL1KuBQc0VIYm1nVF38Sd0gTMSq\"\n",
        "resume_path = \"/content/resume.pdf\"\n",
        "gdown.download(resume_url, resume_path, quiet=False)\n",
        "\n",
        "# Open PDF\n",
        "try:\n",
        "    doc = fitz.open(resume_path)\n",
        "    print(\"✅ PDF opened successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ PDF might be corrupted! Error: {e}\")\n",
        "\n",
        "# Extract Text from Resume\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
        "    return text\n",
        "\n",
        "resume_text = extract_text_from_pdf(resume_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M0iB7hPF_sA"
      },
      "source": [
        "## Converting Text to Embeddings & Storing in FAISS\n",
        "\n",
        "To make search efficient, we **convert text into vector embeddings** using `SentenceTransformers` and **store them in FAISS**.\n",
        "\n",
        "\n",
        "### Steps in this Section\n",
        "* Load a **pretrained embedding model** (`all-MiniLM-L6-v2`).  \n",
        "* Convert **resume text into vector embeddings**.  \n",
        "* Store these embeddings in a **FAISS vector index**.  \n",
        "* Save the FAISS index for **future retrieval**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U09OlIJJ-H9c"
      },
      "outputs": [],
      "source": [
        "# Create Embeddings and FAISS Vector Store\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load SentenceTransformer model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define a wrapper to make it compatible with FAISS\n",
        "class CustomEmbeddings:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        \"\"\"Encodes a list of texts correctly.\"\"\"\n",
        "        if not isinstance(texts, list):\n",
        "            raise ValueError(\"Input to embed_documents() must be a list of strings.\")\n",
        "        return self.model.encode(texts)\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        \"\"\"Encodes a single query correctly.\"\"\"\n",
        "        if not isinstance(text, str):\n",
        "            raise ValueError(\"Input to embed_query() must be a string.\")\n",
        "        return self.model.encode([text])[0]  # Ensure a single embedding is returned\n",
        "\n",
        "    def __call__(self, text):\n",
        "        \"\"\"Makes the class instance callable.\"\"\"\n",
        "        return self.embed_query(text)\n",
        "\n",
        "# Instantiate Embedding Wrapper\n",
        "embedding_function = CustomEmbeddings(embedding_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQaNPOMS8TVe",
        "outputId": "500675f8-3621-4f9d-bb9c-890d7253776a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FAISS Index Created & Saved!\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "import numpy as np\n",
        "\n",
        "# Load embedding model\n",
        "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Wrap embedding model\n",
        "embedding_function = CustomEmbeddings(embedding_model)\n",
        "\n",
        "# Convert resume text into an embedding\n",
        "resume_embedding = embedding_function.embed_documents([resume_text])\n",
        "\n",
        "# Convert embeddings into a NumPy array\n",
        "resume_embedding = np.array(resume_embedding)\n",
        "\n",
        "# Create FAISS Vector Store with Correct Function\n",
        "vector_store = FAISS.from_texts([resume_text], embedding_function)\n",
        "\n",
        "# Save FAISS Index\n",
        "vector_store.save_local(\"faiss_index\")\n",
        "print(\"✅ FAISS Index Created & Saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw-oZEj6GnKJ"
      },
      "source": [
        "## Load OpenAI Model & Set Up RAG Pipeline\n",
        "\n",
        "In this section, we integrate OpenAI’s **GPT model** to generate **fact-based answers** using **retrieved context**.\n",
        "\n",
        "### Why Use RAG?\n",
        "- Instead of asking OpenAI a question blindly, **we first retrieve relevant information** from FAISS.\n",
        "- This makes the responses **more accurate and factually grounded**.\n",
        "\n",
        "### Steps in this Section\n",
        "* Load **gpt-4o-mini**  \n",
        "* Retrieve **relevant resume content** using FAISS.  \n",
        "* Feed the **retrieved content** to GPT before generating a response.  \n",
        "* Ensure **accurate & context-aware responses**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-BItKUvy8eJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70c602b8-a631-44c9-d51e-f195b89a0639"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.vectorstores.faiss:`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RetrievalQA Chain Ready!\n"
          ]
        }
      ],
      "source": [
        "#Load OpenAI Model and Set Up RAG Pipeline\n",
        "import os\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from getpass import getpass\n",
        "\n",
        "# Load FAISS Index with safe deserialization\n",
        "vector_store = FAISS.load_local(\"faiss_index\", embedding_function, allow_dangerous_deserialization=True)\n",
        "\n",
        "# Prompt the user for their OpenAI API key\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# Set the environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "\n",
        "# Use an available model instead of 'gpt-4'\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# Ensure FAISS is correctly loaded\n",
        "vector_store = FAISS.load_local(\"faiss_index\", embedding_function, allow_dangerous_deserialization=True)\n",
        "\n",
        "# Corrected RetrievalQA initialization\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vector_store.as_retriever())\n",
        "\n",
        "print(\"✅ RetrievalQA Chain Ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cSMZsB1HF5A"
      },
      "source": [
        "### Formatting AI Responses for Better Readability\n",
        "\n",
        "AI responses need **clear structure and formatting**. Here, we use `StructuredOutputParser` to ensure responses follow a structured format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1UxLGtMA2syC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6063796d-7c22-41e5-b528-129cfe3b3bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Output Formatting Set Up!\n"
          ]
        }
      ],
      "source": [
        "# Define Output Formatting with Response Schema\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"answer\", description=\"The detailed answer based on resume\"),\n",
        "    ResponseSchema(name=\"source\", description=\"The section of the resume where the information was found\"),\n",
        "]\n",
        "\n",
        "# Initialize Structured Parser\n",
        "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "print(\"✅ Output Formatting Set Up!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xQD0RZkV4Pll"
      },
      "outputs": [],
      "source": [
        "# Define Query Function\n",
        "\n",
        "def ask_question(query):\n",
        "    if not isinstance(query, str):\n",
        "        raise ValueError(\"Query must be a string.\")\n",
        "\n",
        "    cleaned_query = query.strip()  # Remove extra spaces\n",
        "\n",
        "    # Corrected: Call embed_query explicitly\n",
        "    query_embedding = embedding_function.embed_query(cleaned_query)\n",
        "\n",
        "    # Retrieve relevant documents using FAISS\n",
        "    docs = vector_store.similarity_search_by_vector(query_embedding, k=3)\n",
        "\n",
        "    # Query the LLM\n",
        "    response = qa_chain.invoke(cleaned_query)\n",
        "\n",
        "    return {\n",
        "        \"answer\": response[\"result\"],  # Ensure correct key\n",
        "        \"source\": [doc.page_content for doc in docs]  # Extract text from retrieved documents\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "w_ufhV0g9-Kq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a4edea-3405-4259-a9b4-78b3da03f527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: Where do I currently study?\n",
            "Answer: You currently study at Northeastern University in Boston, MA.\n",
            "Source: ['Srishti C Rai\\nBoston, MA \\x83 (413) 419-6505 # srishtiraic@gmail.com ï linkedin.com/in/srishti-c-rai § github.com/srishtirai\\nEDUCATION\\nNortheastern University\\nExpected Jul 2025\\nMaster of Science, Software Engineering Systems (3.8 GPA)\\nBoston, MA\\nRNS Institute of Technology\\nAug 2020\\nBachelor of Engineering, Computer Science & Engineering\\nBangalore, India\\nTECHNICAL SKILLS\\n• Programming Languages: Java, JavaScript, TypeScript, Python, Dart, C#\\n• Frontend Development: HTML, CSS, React, Next.js, Sass, Bootstrap, Redux, AJAX, Webpack, Flutter, Figma\\n• Backend Development: JSP, Flask, REST API, Spring Boot, JSON, Nest.js, ASP.NET\\nTesting: Selenium, Jest\\n• Database: SQL, MySQL, PostgreSQL, MSSQL Cloud: AWS (S3, IAM, EC2), Azure DevOps: Docker, Octopus\\nEXPERIENCE\\nSoftware Development Intern\\nMay 2024 – Dec 2024\\nSentinel Group\\nWakefield, MA\\n• Developed a NestJS solution that fully automates folder creation and permission assignment, reducing setup time by 80%.\\n• Engineered an audit feature to track naming and folder structure conventions and permissions, storing results in\\nPostgreSQL, identifying 95% of permission inconsistencies, and enhancing compliance verification.\\n• Created an intuitive admin interface with Next.js, integrating breadcrumb navigation and streamlined review workflows to\\nsimplify folder management for administrators.\\nResearch Engineer (Full Stack Developer)\\nJul 2021 – Aug 2023\\nLG Soft India\\nBangalore, India\\n• Built an interactive React application for the OTA updates portal, integrating Battery Management System data to manage\\nand monitor battery site statuses and firmware updates. Boosted modularity by 60% with a reusable component library.\\n• Collaborated in South Korea with the UI/UX team to integrate user-focused features, reducing reported issues by 40%.\\n• Designed and developed authentication and authorization APIs in Spring Boot, implementing JWT-based token\\nmanagement and role-based access control to ensure secure, scalable access to the platform.\\n• Optimized AWS S3 uploads with concurrency and integrity checks, reducing upload time by 55% and boosting security.\\n• Mentored 5 interns, providing guidance and training in building web applications and standard coding practices.\\n• Awards: LGSI Spotlight Awards - Aug 2022, Hero of the Month Spot Awards - Nov 2021\\nSoftware Engineer\\nJul 2020 – Jun 2021\\nLG Soft India\\nBangalore, India\\n• Developed Gallery & Calendar apps using EnactJS for TV and signage, contributing to the webOS ecosystem.\\n• Created a Flutter POC with network and Bluetooth features, identifying webOS compatibility issues.\\nLEADERSHIP & MENTORSHIP\\nTeaching Assistant (TA) & Mentor\\nJan 2025 - Apr 2025\\nNortheastern University\\nBoston, MA\\n• Assisting with course delivery, grading, and supporting students in the Concepts of Object-Oriented Design course.\\n• Mentoring students in the Oasis Program, helping them build their first website or app, and advising on tools and design.\\nPROJECTS\\nMovie Booking Application | Java, Spring Boot, Hibernate, MySQL, Thymleaf\\n• Engineered a movie booking system using Spring Boot, enabling functionalities like viewing, searching, and booking.\\n• Enhanced system security by implementing role-based authentication and authorization with Spring Security.\\n• Optimized database performance with Hibernate DAOs and streamlined data migration for efficiency.\\nStock Price Prediction | Flask, Python, JavaScript, Scikit-learn, Pandas, NumPy, Matplotlib\\n• Developed a Flask-based web application allowing users to view predicted closing stock prices for various companies.\\n• Utilized clustering and classification models on historical stock data, delivering insights through interactive visualizations.\\nHostel Management System | C#, Windows Forms(.NET), Oracle Database\\n• Crafted a comprehensive Oracle database system for managing student records and hostel accommodation details.\\n• Implemented an interactive ASP.NET Web Forms UI with the MVC pattern to optimize user experience and functionality.\\n']\n"
          ]
        }
      ],
      "source": [
        "query = \"Where do I currently study?\"\n",
        "result = ask_question(query)\n",
        "\n",
        "# Display Answer\n",
        "print(\"\\nQuestion:\", query)\n",
        "print(\"Answer:\", result[\"answer\"])\n",
        "print(\"Source:\", result[\"source\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lofuGOW7HYyB"
      },
      "source": [
        "### Interactive Q&A with User Input\n",
        "\n",
        "This section allows **users to dynamically ask questions** and get fact-based answers.\n",
        "\n",
        "* The system **continuously waits for user input**.  \n",
        "* The input question is **converted into an embedding**.  \n",
        "* FAISS **retrieves relevant documents** from the resume.  \n",
        "* The retrieved content is **fed into OpenAI** for an accurate response.  \n",
        "* The answer and **source document** are printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2sUWFNa9B02M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b22d4fdf-44be-4bbd-9ddd-b9a82227280b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Ask a question (or type 'exit' to quit): Summarise my work experince and skills\n",
            "\n",
            "Answer: You have a strong background in software development with experience in both full-stack and backend roles. \n",
            "\n",
            "**Work Experience:**\n",
            "1. **Software Development Intern at Sentinel Group (May 2024 – Dec 2024)**: Developed a NestJS solution for automating folder creation and permissions, engineered an audit feature for compliance verification, and created an admin interface using Next.js.\n",
            "   \n",
            "2. **Research Engineer (Full Stack Developer) at LG Soft India (Jul 2021 – Aug 2023)**: Built a React application for OTA updates, collaborated with UI/UX teams in South Korea, designed secure APIs in Spring Boot, optimized AWS S3 uploads, and mentored interns.\n",
            "\n",
            "3. **Software Engineer at LG Soft India (Jul 2020 – Jun 2021)**: Developed applications for the webOS ecosystem using EnactJS and created a Flutter proof of concept.\n",
            "\n",
            "**Technical Skills:**\n",
            "- **Programming Languages**: Java, JavaScript, TypeScript, Python, Dart, C#\n",
            "- **Frontend Development**: HTML, CSS, React, Next.js, Sass, Bootstrap, Redux, AJAX, Webpack, Flutter, Figma\n",
            "- **Backend Development**: JSP, Flask, REST API, Spring Boot, JSON, Nest.js, ASP.NET\n",
            "- **Testing**: Selenium, Jest\n",
            "- **Database**: SQL, MySQL, PostgreSQL, MSSQL\n",
            "- **Cloud**: AWS (S3, IAM, EC2), Azure\n",
            "- **DevOps**: Docker, Octopus\n",
            "\n",
            "Overall, you have demonstrated strong technical skills and practical experience in software engineering, with a focus on developing efficient and user-friendly applications.\n",
            "Source: ['Srishti C Rai\\nBoston, MA \\x83 (413) 419-6505 # srishtiraic@gmail.com ï linkedin.com/in/srishti-c-rai § github.com/srishtirai\\nEDUCATION\\nNortheastern University\\nExpected Jul 2025\\nMaster of Science, Software Engineering Systems (3.8 GPA)\\nBoston, MA\\nRNS Institute of Technology\\nAug 2020\\nBachelor of Engineering, Computer Science & Engineering\\nBangalore, India\\nTECHNICAL SKILLS\\n• Programming Languages: Java, JavaScript, TypeScript, Python, Dart, C#\\n• Frontend Development: HTML, CSS, React, Next.js, Sass, Bootstrap, Redux, AJAX, Webpack, Flutter, Figma\\n• Backend Development: JSP, Flask, REST API, Spring Boot, JSON, Nest.js, ASP.NET\\nTesting: Selenium, Jest\\n• Database: SQL, MySQL, PostgreSQL, MSSQL Cloud: AWS (S3, IAM, EC2), Azure DevOps: Docker, Octopus\\nEXPERIENCE\\nSoftware Development Intern\\nMay 2024 – Dec 2024\\nSentinel Group\\nWakefield, MA\\n• Developed a NestJS solution that fully automates folder creation and permission assignment, reducing setup time by 80%.\\n• Engineered an audit feature to track naming and folder structure conventions and permissions, storing results in\\nPostgreSQL, identifying 95% of permission inconsistencies, and enhancing compliance verification.\\n• Created an intuitive admin interface with Next.js, integrating breadcrumb navigation and streamlined review workflows to\\nsimplify folder management for administrators.\\nResearch Engineer (Full Stack Developer)\\nJul 2021 – Aug 2023\\nLG Soft India\\nBangalore, India\\n• Built an interactive React application for the OTA updates portal, integrating Battery Management System data to manage\\nand monitor battery site statuses and firmware updates. Boosted modularity by 60% with a reusable component library.\\n• Collaborated in South Korea with the UI/UX team to integrate user-focused features, reducing reported issues by 40%.\\n• Designed and developed authentication and authorization APIs in Spring Boot, implementing JWT-based token\\nmanagement and role-based access control to ensure secure, scalable access to the platform.\\n• Optimized AWS S3 uploads with concurrency and integrity checks, reducing upload time by 55% and boosting security.\\n• Mentored 5 interns, providing guidance and training in building web applications and standard coding practices.\\n• Awards: LGSI Spotlight Awards - Aug 2022, Hero of the Month Spot Awards - Nov 2021\\nSoftware Engineer\\nJul 2020 – Jun 2021\\nLG Soft India\\nBangalore, India\\n• Developed Gallery & Calendar apps using EnactJS for TV and signage, contributing to the webOS ecosystem.\\n• Created a Flutter POC with network and Bluetooth features, identifying webOS compatibility issues.\\nLEADERSHIP & MENTORSHIP\\nTeaching Assistant (TA) & Mentor\\nJan 2025 - Apr 2025\\nNortheastern University\\nBoston, MA\\n• Assisting with course delivery, grading, and supporting students in the Concepts of Object-Oriented Design course.\\n• Mentoring students in the Oasis Program, helping them build their first website or app, and advising on tools and design.\\nPROJECTS\\nMovie Booking Application | Java, Spring Boot, Hibernate, MySQL, Thymleaf\\n• Engineered a movie booking system using Spring Boot, enabling functionalities like viewing, searching, and booking.\\n• Enhanced system security by implementing role-based authentication and authorization with Spring Security.\\n• Optimized database performance with Hibernate DAOs and streamlined data migration for efficiency.\\nStock Price Prediction | Flask, Python, JavaScript, Scikit-learn, Pandas, NumPy, Matplotlib\\n• Developed a Flask-based web application allowing users to view predicted closing stock prices for various companies.\\n• Utilized clustering and classification models on historical stock data, delivering insights through interactive visualizations.\\nHostel Management System | C#, Windows Forms(.NET), Oracle Database\\n• Crafted a comprehensive Oracle database system for managing student records and hostel accommodation details.\\n• Implemented an interactive ASP.NET Web Forms UI with the MVC pattern to optimize user experience and functionality.\\n']\n",
            "\n",
            "Ask a question (or type 'exit' to quit): Is srishti a full stack developer?\n",
            "\n",
            "Answer: Yes, Srishti C Rai is a full stack developer, as indicated by her experience as a Research Engineer (Full Stack Developer) where she built interactive applications and developed both frontend and backend components.\n",
            "Source: ['Srishti C Rai\\nBoston, MA \\x83 (413) 419-6505 # srishtiraic@gmail.com ï linkedin.com/in/srishti-c-rai § github.com/srishtirai\\nEDUCATION\\nNortheastern University\\nExpected Jul 2025\\nMaster of Science, Software Engineering Systems (3.8 GPA)\\nBoston, MA\\nRNS Institute of Technology\\nAug 2020\\nBachelor of Engineering, Computer Science & Engineering\\nBangalore, India\\nTECHNICAL SKILLS\\n• Programming Languages: Java, JavaScript, TypeScript, Python, Dart, C#\\n• Frontend Development: HTML, CSS, React, Next.js, Sass, Bootstrap, Redux, AJAX, Webpack, Flutter, Figma\\n• Backend Development: JSP, Flask, REST API, Spring Boot, JSON, Nest.js, ASP.NET\\nTesting: Selenium, Jest\\n• Database: SQL, MySQL, PostgreSQL, MSSQL Cloud: AWS (S3, IAM, EC2), Azure DevOps: Docker, Octopus\\nEXPERIENCE\\nSoftware Development Intern\\nMay 2024 – Dec 2024\\nSentinel Group\\nWakefield, MA\\n• Developed a NestJS solution that fully automates folder creation and permission assignment, reducing setup time by 80%.\\n• Engineered an audit feature to track naming and folder structure conventions and permissions, storing results in\\nPostgreSQL, identifying 95% of permission inconsistencies, and enhancing compliance verification.\\n• Created an intuitive admin interface with Next.js, integrating breadcrumb navigation and streamlined review workflows to\\nsimplify folder management for administrators.\\nResearch Engineer (Full Stack Developer)\\nJul 2021 – Aug 2023\\nLG Soft India\\nBangalore, India\\n• Built an interactive React application for the OTA updates portal, integrating Battery Management System data to manage\\nand monitor battery site statuses and firmware updates. Boosted modularity by 60% with a reusable component library.\\n• Collaborated in South Korea with the UI/UX team to integrate user-focused features, reducing reported issues by 40%.\\n• Designed and developed authentication and authorization APIs in Spring Boot, implementing JWT-based token\\nmanagement and role-based access control to ensure secure, scalable access to the platform.\\n• Optimized AWS S3 uploads with concurrency and integrity checks, reducing upload time by 55% and boosting security.\\n• Mentored 5 interns, providing guidance and training in building web applications and standard coding practices.\\n• Awards: LGSI Spotlight Awards - Aug 2022, Hero of the Month Spot Awards - Nov 2021\\nSoftware Engineer\\nJul 2020 – Jun 2021\\nLG Soft India\\nBangalore, India\\n• Developed Gallery & Calendar apps using EnactJS for TV and signage, contributing to the webOS ecosystem.\\n• Created a Flutter POC with network and Bluetooth features, identifying webOS compatibility issues.\\nLEADERSHIP & MENTORSHIP\\nTeaching Assistant (TA) & Mentor\\nJan 2025 - Apr 2025\\nNortheastern University\\nBoston, MA\\n• Assisting with course delivery, grading, and supporting students in the Concepts of Object-Oriented Design course.\\n• Mentoring students in the Oasis Program, helping them build their first website or app, and advising on tools and design.\\nPROJECTS\\nMovie Booking Application | Java, Spring Boot, Hibernate, MySQL, Thymleaf\\n• Engineered a movie booking system using Spring Boot, enabling functionalities like viewing, searching, and booking.\\n• Enhanced system security by implementing role-based authentication and authorization with Spring Security.\\n• Optimized database performance with Hibernate DAOs and streamlined data migration for efficiency.\\nStock Price Prediction | Flask, Python, JavaScript, Scikit-learn, Pandas, NumPy, Matplotlib\\n• Developed a Flask-based web application allowing users to view predicted closing stock prices for various companies.\\n• Utilized clustering and classification models on historical stock data, delivering insights through interactive visualizations.\\nHostel Management System | C#, Windows Forms(.NET), Oracle Database\\n• Crafted a comprehensive Oracle database system for managing student records and hostel accommodation details.\\n• Implemented an interactive ASP.NET Web Forms UI with the MVC pattern to optimize user experience and functionality.\\n']\n",
            "\n",
            "Ask a question (or type 'exit' to quit): Is she an artist?\n",
            "\n",
            "Answer: I don't know.\n",
            "Source: ['Srishti C Rai\\nBoston, MA \\x83 (413) 419-6505 # srishtiraic@gmail.com ï linkedin.com/in/srishti-c-rai § github.com/srishtirai\\nEDUCATION\\nNortheastern University\\nExpected Jul 2025\\nMaster of Science, Software Engineering Systems (3.8 GPA)\\nBoston, MA\\nRNS Institute of Technology\\nAug 2020\\nBachelor of Engineering, Computer Science & Engineering\\nBangalore, India\\nTECHNICAL SKILLS\\n• Programming Languages: Java, JavaScript, TypeScript, Python, Dart, C#\\n• Frontend Development: HTML, CSS, React, Next.js, Sass, Bootstrap, Redux, AJAX, Webpack, Flutter, Figma\\n• Backend Development: JSP, Flask, REST API, Spring Boot, JSON, Nest.js, ASP.NET\\nTesting: Selenium, Jest\\n• Database: SQL, MySQL, PostgreSQL, MSSQL Cloud: AWS (S3, IAM, EC2), Azure DevOps: Docker, Octopus\\nEXPERIENCE\\nSoftware Development Intern\\nMay 2024 – Dec 2024\\nSentinel Group\\nWakefield, MA\\n• Developed a NestJS solution that fully automates folder creation and permission assignment, reducing setup time by 80%.\\n• Engineered an audit feature to track naming and folder structure conventions and permissions, storing results in\\nPostgreSQL, identifying 95% of permission inconsistencies, and enhancing compliance verification.\\n• Created an intuitive admin interface with Next.js, integrating breadcrumb navigation and streamlined review workflows to\\nsimplify folder management for administrators.\\nResearch Engineer (Full Stack Developer)\\nJul 2021 – Aug 2023\\nLG Soft India\\nBangalore, India\\n• Built an interactive React application for the OTA updates portal, integrating Battery Management System data to manage\\nand monitor battery site statuses and firmware updates. Boosted modularity by 60% with a reusable component library.\\n• Collaborated in South Korea with the UI/UX team to integrate user-focused features, reducing reported issues by 40%.\\n• Designed and developed authentication and authorization APIs in Spring Boot, implementing JWT-based token\\nmanagement and role-based access control to ensure secure, scalable access to the platform.\\n• Optimized AWS S3 uploads with concurrency and integrity checks, reducing upload time by 55% and boosting security.\\n• Mentored 5 interns, providing guidance and training in building web applications and standard coding practices.\\n• Awards: LGSI Spotlight Awards - Aug 2022, Hero of the Month Spot Awards - Nov 2021\\nSoftware Engineer\\nJul 2020 – Jun 2021\\nLG Soft India\\nBangalore, India\\n• Developed Gallery & Calendar apps using EnactJS for TV and signage, contributing to the webOS ecosystem.\\n• Created a Flutter POC with network and Bluetooth features, identifying webOS compatibility issues.\\nLEADERSHIP & MENTORSHIP\\nTeaching Assistant (TA) & Mentor\\nJan 2025 - Apr 2025\\nNortheastern University\\nBoston, MA\\n• Assisting with course delivery, grading, and supporting students in the Concepts of Object-Oriented Design course.\\n• Mentoring students in the Oasis Program, helping them build their first website or app, and advising on tools and design.\\nPROJECTS\\nMovie Booking Application | Java, Spring Boot, Hibernate, MySQL, Thymleaf\\n• Engineered a movie booking system using Spring Boot, enabling functionalities like viewing, searching, and booking.\\n• Enhanced system security by implementing role-based authentication and authorization with Spring Security.\\n• Optimized database performance with Hibernate DAOs and streamlined data migration for efficiency.\\nStock Price Prediction | Flask, Python, JavaScript, Scikit-learn, Pandas, NumPy, Matplotlib\\n• Developed a Flask-based web application allowing users to view predicted closing stock prices for various companies.\\n• Utilized clustering and classification models on historical stock data, delivering insights through interactive visualizations.\\nHostel Management System | C#, Windows Forms(.NET), Oracle Database\\n• Crafted a comprehensive Oracle database system for managing student records and hostel accommodation details.\\n• Implemented an interactive ASP.NET Web Forms UI with the MVC pattern to optimize user experience and functionality.\\n']\n",
            "\n",
            "Ask a question (or type 'exit' to quit): exit\n",
            "Exiting Interactive Q&A. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "def interactive_qa():\n",
        "    while True:\n",
        "        query = input(\"\\nAsk a question (or type 'exit' to quit): \").strip()\n",
        "\n",
        "        if query.lower() == \"exit\":\n",
        "            print(\"Exiting Interactive Q&A. Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Get the answer using the RAG pipeline\n",
        "        result = ask_question(query)\n",
        "\n",
        "        # Print the response\n",
        "        print(\"\\nAnswer:\", result[\"answer\"])\n",
        "        print(\"Source:\", result[\"source\"])\n",
        "\n",
        "# Run the interactive Q&A\n",
        "interactive_qa()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13R7TWAPDjQz"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}